"""
Trvi.io job used to extract features from the common crawl corpus
"""

common_crawl_url = 's3://aws-publicdatasets/common-crawl/crawl-002/'

cc_features = rule(common_crawl_url,'cc_features')
cc_features.param('maxinput', 1)
cc_features.param('unique_items', True)

from disco.worker.classic.func import discodb_stream
cc_features.reduce_output_stream = discodb_stream


@cc_features.map_reader
def beautiful_soup(stream, size, url, params):
  from bs4 import BeautifulSoup, SoupStrainer
  import time


  # bs4 uses the warnings module which writes to stderr.
  # this breaks disco which uses stderr for communicating
  # to it's worker process.

  import warnings, sys
 
  def customwarn(message, category, filename, lineno, file=None, line=None):
    sys.stdout.write(warnings.formatwarning(message, category, filename, lineno))
  warnings.showwarning = customwarn

  start = time.time()
  count = 0
  eo_headers = '\r\n\r\n'
  for doc in stream:
    count += 1
    #if count > 150:
    #  return
    
    if time.time() - start > 1:
      print "docs {}".format(count)
      start = time.time()

    eoh_pos = doc['payload'].find(eo_headers)
    if eoh_pos > -1:
      doc['headers'] = dict([
        h.split(':',1)
        for h in doc['payload'][:eoh_pos].split('\r\n')[1:]
        if h
      ])

    if doc['content_type'] == 'text/html':
      try:
        doc['dom'] = BeautifulSoup(doc['payload'])
      except Exception, e:
        doc['parse_exception'] = e
    yield doc

@cc_features.map
def index(doc, params):
  from features import extractor
  return extractor(doc, params)

@cc_features.reduce
def reduce(iter, params):
  from features import schema
  from string import digits

  yield "__schema__", json.dumps(schema.to_dict())

   
  record_count = 0

  for k,v in iter:
    if k[0] in digits:
      # it's a record
      record_count += 1

    # ('link:http:/foo.com', 2) -> ('link:http:/foo.com', '2')
    yield k, str(v)
    p = k.split(':',1)
    if len(p) == 2:
      # 'link:http:/foo.com' -> ('link', 'link:http:/foo.com')
      yield p[0], k

  yield "__count__", str(record_count)
 